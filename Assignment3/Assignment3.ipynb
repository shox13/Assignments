{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Data Using Machine Learning\n",
    "## Multivariate Linear Regression\n",
    "\n",
    "Being able to accurately price listings is important for real estate agents.\n",
    "If they price too high, their client's home won't sell as fast. And if they price too low, they leave money on the table. Our friend the real estate agent can use linear and logistic regression to make her and her clients' lives easier.\n",
    "\n",
    "Say a client comes to her to sell home in  Boston, which has the following features:\n",
    "\n",
    "- CRIM     per capita crime rate by town\n",
    "- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS    proportion of non-retail business acres per town\n",
    "- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX      nitric oxides concentration (parts per 10 million)\n",
    "- RM       average number of rooms per dwelling\n",
    "- AGE      proportion of owner-occupied units built prior to 1940\n",
    "- DIS      weighted distances to five Boston employment centres\n",
    "- RAD      index of accessibility to radial highways\n",
    "- TAX      full-value property-tax rate per 10,000\n",
    "- PTRATIO  pupil-teacher ratio by town\n",
    "- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT    % lower status of the population\n",
    "- MEDV     Median value of owner-occupied homes in 1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "Lucky for the client, she has a set of data on Boston housing from 1978! She'll\n",
    "create a model that she can then plug the client's data into and come up with an\n",
    "estimate for selling price.\n",
    "\n",
    "The code below uses multivariate linear regression to plot expected and real median home values.\n",
    "\n",
    "Run the cell below to see the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_regr(X,y,regr, title, size = 10):\n",
    "    \n",
    "    regr.fit(X, y)\n",
    "\n",
    "    y_pred = regr.predict(X)\n",
    "    plt.clf()\n",
    "    plt.plot(y, y_pred, 'o')\n",
    "\n",
    "    perfect_fit = np.linspace(y.min(),y.max(), 20)\n",
    "    plt.plot(perfect_fit, perfect_fit, 'b--', label='Perfect Fit')\n",
    "\n",
    "    \n",
    "    plt.text(5, 40, \"$R^2$ = %.2f\" % regr.score(X,y))\n",
    "    plt.title(title, size = size)\n",
    "    plt.xlabel('True MEDV ($1,000s)')\n",
    "    plt.ylabel('Predicted MEDV ($1,000s)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def write_equn(a, b, regr):\n",
    "\n",
    "    regr.fit(a,b)\n",
    "\n",
    "    equn = 'MEDV = %.2f' % regr.intercept_\n",
    "    for feat, val in zip(data.feature_names, regr.coef_):\n",
    "        if val > 0:\n",
    "            equn += ' + %.2f*%s' % (val, feat)\n",
    "        else:\n",
    "            equn += ' - %.2f*%s' % (abs(val), feat)\n",
    "    return equn\n",
    "\n",
    "data = load_boston()\n",
    "X = data.data\n",
    "y = data.target\n",
    "lin = linear_model.LinearRegression()\n",
    "\n",
    "title = 'True vs. Predicted MEDV (whole set) by Multivariate Linear Regression'\n",
    "plot_regr(X, y, lin, title)\n",
    "equn_whole = write_equn(X,y, lin)\n",
    "print(\"The model found for the whole dataset:\\n{}\\n\".format(equn_whole))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate MDEV for the house to cell\n",
    "The real estate agent now has a model with a lot of variables. All she has to do is plug in\n",
    "the correct information from her client's home and she can estimate its price. She was\n",
    "able to gather some of the information on her client's home:\n",
    "        - CRIM     per capita crime rate by town\n",
    "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "        - INDUS    proportion of non-retail business acres per town\n",
    "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "        - NOX      nitric oxides concentration (parts per 10 million)\n",
    "        - RM       5\n",
    "        - AGE      proportion of owner-occupied units built prior to 1940\n",
    "        - DIS      2.5\n",
    "        - RAD      index of accessibility to radial highways\n",
    "        - TAX      700\n",
    "        - PTRATIO  pupil-teacher ratio by town\n",
    "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "        - LSTAT    % lower status of the population\n",
    "        - MEDV     Median value of owner-occupied homes in $1000's\n",
    "\n",
    "We'll plug in the mean values for the values we don't have, which assumes her\n",
    "home is average for those features.\n",
    "\n",
    "Run the two following cells to see a estimate for the home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "example = np.array([X.mean(axis=0)]).ravel()\n",
    "example[5] = 5\n",
    "example[7] = 2.5\n",
    "example[9] = 700\n",
    "example = example.reshape(1,-1)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [],
   "source": [
    "lin = linear_model.LinearRegression()\n",
    "lin.fit(X,y)\n",
    "y_pred = lin.predict(example)\n",
    "print(\"She should price her client's home at $%5.2f, which is lower than the average price of $%5.2f\" %\n",
    "      (y_pred*1000, y.mean()*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home price results\n",
    "The agent used the model, plugged in either the mean or the actual value if she had\n",
    "it, and the model returned an estimate you see above. This price will best balance\n",
    "selling her client's home in a timely manner and not leaving any money on the\n",
    "table.\n",
    "\n",
    "Before she gets too confident about her prediction, she has to beware of a\n",
    "couple of pitfalls: overfitting and applicability of the model. When she trains\n",
    "her model on this Boston housing data set, it's learning the characteristics\n",
    "of that data, or overfitting. It's an open question how well that data \n",
    "represents a house not in the dataset. For example, if the dataset were made up of trailer \n",
    "homes, it won't do well predicting price for a condo. The following image\n",
    "illustrates under vs. overfitting:\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS7NQXhuJ5ZwFJnTv8CYnrYqfQOM4m0Q6fTE-mesM_AV3SbnnIl1g)\n",
    "\n",
    "She needs something that makes her confident that her model isn't overfitting and that\n",
    "she can use it on a variety of homes. To deal with overfitting, she can use\n",
    "**regularization**, which reduces the tendency of her model to learn the data in\n",
    "the dataset, aka overfitting. The following image shows how regularization moves the \n",
    "overfit model toward something closer to \"just right\" by penalizing high values\n",
    "of $\\theta_3$ and $\\theta_4$.\n",
    "\n",
    "![](http://www.holehouse.org/mlclass/07_Regularization_files/Image.png)\n",
    "\n",
    "To answer the question, \"Does this model actually work for my clients?\" \n",
    "she will use the training data to also test the model. This is a good way to \n",
    "confirm applicability. The following image illustrates how she will implement\n",
    "cross-validation, or the applicability test for her dataset: \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg)\n",
    "\n",
    "Run the cell below to see the results or regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ridge regression\n",
    "ridge = linear_model.Ridge(alpha=1.0)\n",
    "title = 'True vs. Predicted MEDV by Multivariate Linear '+\\\n",
    "        'Regression with Ridge Regularization'\n",
    "plot_regr(X, y, ridge, title)\n",
    "equn_ridge = write_equn(X,y, ridge)\n",
    "print(\"The model found by Ridge Regression:\\n{}\\n\".format(equn_ridge))\n",
    "\n",
    "# LASSO regression\n",
    "lasso = linear_model.Lasso(alpha=1.0)\n",
    "title = 'True vs. Predicted MEDV by Multivariate Linear '+\\\n",
    "        'Regression with LASSO Regularization'\n",
    "plot_regr(X, y, lasso, title)\n",
    "equn_lasso = write_equn(X,y, lasso)\n",
    "print(\"The model found by LASSO Regression:\\n{}\\n\".format(equn_lasso))\n",
    "\n",
    "# Elastic-Net regression\n",
    "el_net = linear_model.ElasticNet()\n",
    "title = 'True vs. Predicted MEDV by Multivariate Linear '+\\\n",
    "        'Regression with Elastic Net Regularization'\n",
    "plot_regr(X, y, el_net, title)\n",
    "equn_el_net = write_equn(X,y, el_net)\n",
    "print(\"The model found by Elastic Net Regression:\\n{}\\n\".format(equn_el_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "Regularization tends to push the value of the learned parameters lower,\n",
    "sometimes to zero, by deciding whether a feature (such as CRIM, RM, and others) is\n",
    "actually a good predictor. The result is a less complex model less prone to\n",
    "overfitting. \n",
    "\n",
    "Other questions she has are: \n",
    "- Does this model work? \n",
    "- Can I use this to price a house on the north side of the city or the south? \n",
    "\n",
    "By creating a train and test split (cross-validation) from the data, she can test the model on data\n",
    "it hasn't yet seen. If the model works well on the test set, she can feel more confident.\n",
    "\n",
    "Run the cell below to see the results for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "17"
    }
   },
   "outputs": [],
   "source": [
    "# split data into train/test sets and show fit \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)\n",
    "\n",
    "title = 'True vs. Predicted MEDV (train set) by Multivariate Linear Regression'\n",
    "plot_regr(X_train, y_train, lin, title)\n",
    "equn_train = write_equn(X_train, y_train, lin)\n",
    "print(\"The model found for the train dataset:\\n{}\\n\".format(equn_train))\n",
    "\n",
    "title = 'True vs. Predicted MEDV (test set) by Multivariate Linear Regression'\n",
    "plot_regr(X_test, y_test, lin, title)\n",
    "equn_test = write_equn(X_test, y_test, lin)\n",
    "print(\"The model found for the test dataset:\\n{}\\n\".format(equn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "As you can see above, the train set has a higher $R^2$ value compared to the test set-the $R^2$ value\n",
    "is in [0,1], and it measures how well the model explains the dataset. This\n",
    "happens because the model hasn't seen those data points yet. Even still, the\n",
    "fit is good and it should help her to price her client's home.\n",
    "\n",
    "To sum up, she used a model built from past data on Boston housing to give\n",
    "her client a good estimate of sale price. She used **regularization** to reduce the \n",
    "chances her model had only learned the data from the dataset. And, she split\n",
    "up the data into train and test sets to test/cross-validate how well it did on\n",
    "new data; therefore, she can be confident in feeding it new data from her \n",
    "clients that it was not originally trained on.\n",
    "\n",
    "Next, we'll use use multivariate logistic regression with the same dataset to decide whether \n",
    "adding a bedroom to a house will pay off. \n",
    "\n",
    "## Multivariate Logistic Regression\n",
    "\n",
    "Previously, we saw how a real estate agent could make a model to accurately\n",
    "price her client's home to balance time on the market and not leaving money on\n",
    "the table. \n",
    "\n",
    "Now, the agent has a client who wants to add a bedroom to\n",
    "his home, but he's wondering how it will affect the value and whether he will\n",
    "recoup his investment. More precisely, he wants to know the probability that his home\n",
    "will be worth more than the average home price in his neighborhood after the \n",
    "addition. He's in luck, because she has a multivariate logistic regression \n",
    "model she's been waiting to put to use!\n",
    "\n",
    "As a reminder her model has the following features:\n",
    "\n",
    "- CRIM     per capita crime rate by town\n",
    "- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS    proportion of non-retail business acres per town\n",
    "- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX      nitric oxides concentration (parts per 10 million)\n",
    "- RM       average number of rooms per dwelling\n",
    "- AGE      proportion of owner-occupied units built prior to 1940\n",
    "- DIS      weighted distances to five Boston employment centres\n",
    "- RAD      index of accessibility to radial highways\n",
    "- TAX      full-value property-tax rate per $10,000\n",
    "- PTRATIO  pupil-teacher ratio by town\n",
    "- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT    % lower status of the population\n",
    "- MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The home owner gives the agent the following information on his house:\n",
    "\n",
    "- CRIM     8.5\n",
    "- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS    proportion of non-retail business acres per town\n",
    "- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX      nitric oxides concentration (parts per 10 million)\n",
    "- RM       3\n",
    "- AGE      proportion of owner-occupied units built prior to 1940\n",
    "- DIS      1.5\n",
    "- RAD      index of accessibility to radial highways\n",
    "- TAX      650\n",
    "- PTRATIO  pupil-teacher ratio by town\n",
    "- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT    % lower status of the population\n",
    "- MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use logistic regression\n",
    "Now, using logistic regression, she can give him the probability his house price, after the addition, will be greater than the mean house value for his region.\n",
    "\n",
    "Run the cell below to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scikitplot.plotters as skplt\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc(X,y,regr, title, size = 10):\n",
    "    \n",
    "    regr.fit(X, y)\n",
    "\n",
    "    y_pred = regr.predict_proba(X)\n",
    "    skplt.plot_roc_curve(y, y_pred, title = title)\n",
    "    plt.show()\n",
    "\n",
    "def write_equn(a, b, regr):\n",
    "\n",
    "    regr.fit(a,b)\n",
    "\n",
    "    equn = 'MEDV = %.2f' % regr.intercept_\n",
    "    for feat, val in zip(data.feature_names, regr.coef_.T):\n",
    "        if val > 0:\n",
    "            equn += ' + %.2f*%s' % (val, feat)\n",
    "        else:\n",
    "            equn += ' - %.2f*%s' % (abs(val), feat)\n",
    "    return equn\n",
    "def classify(y, threshold):\n",
    "    y_clf = []\n",
    "    for val in y:\n",
    "        if val > threshold:\n",
    "            y_clf.append(1)\n",
    "        else:\n",
    "            y_clf.append(0)\n",
    "\n",
    "    return np.array(y_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify data with an ROC curve\n",
    "Next, we will fit our logistic regression model and see how well it classifies our\n",
    "data with an ROC curve. As a reminder on ROC curves, they're measuring how well \n",
    "the model classifies data points. In our case, that corresponds to correctly \n",
    "labelling points with values (MEDV) greater than the mean versus those less than. \n",
    "Additionally, an area of 1 is the max score possible, so .95 is pretty good and \n",
    "shows our model works well as a classifier.\n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X = data.data\n",
    "target_mean = classify(data.target, data.target.mean())\n",
    "\n",
    "log = linear_model.LogisticRegression()\n",
    "\n",
    "title = 'ROC Curve for Multivariate Logistic Regression (whole set)'\n",
    "plot_roc(X, target_mean, log, title)\n",
    "equn_whole = write_equn(X,target_mean, log)\n",
    "print(\"The model found for the whole dataset:\\n{}\\n\".format(equn_whole))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the probability\n",
    "Your task is to predict the probability the client's home will be worth more than \n",
    "average after adding an additional room. You will need to:\n",
    "\n",
    "- fill in the corresponding values for his home\n",
    "- fill in the mean for all missing values\n",
    "- add the vector as the variable to the call to log.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to pull up documentation\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "?np.ravel\n",
    "# Uncomment the next line to see documentation for np.mean\n",
    "#?np.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the values for the `example` array below, using the previous code as an example.\n",
    "\n",
    "Try it first.  You can check your code against the answer in the cell that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#--------------------------Enter your Code Here-------------#\n",
    "example = \n",
    "\n",
    "log.fit(X, target_mean)\n",
    "print(\"P(MEDV > mean | RM=4; CRIM=0; DIS=1.5; TAX=650) = %.2f\" % log.predict_proba(example)[0,1])\n",
    "#------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer code\n",
    "Try the following code in the cell above.\n",
    "\n",
    "```python\n",
    "example = np.array([X.mean(axis=0)]).ravel()\n",
    "example[0] = 8.5\n",
    "# 3+1 RMs after the addition\n",
    "example[5] = 4\n",
    "example[7] = 1.5\n",
    "example[9] = 650\n",
    "example = example.reshape(1,-1)\n",
    "\n",
    "log.fit(X, target_mean)\n",
    "print(\"P(MEDV > mean | RM=4; CRIM=0; DIS=1.5; TAX=650) = %.2f\" % log.predict_proba(example)[0,1])\n",
    "```\n",
    "Run the cell below to see the mean RMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [],
   "source": [
    "# mean number of RMs\n",
    "X[:,5].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Unfortunately, the probability of his house being greater than average post-\n",
    "addition is only 1% and our model would predict the 0 class (instead of 1). The \n",
    "mean number of rooms is 6.28, yet the client only has 4. So, it makes sense this \n",
    "house sells for a discount.\n",
    "\n",
    "# Regularization\n",
    "\n",
    "As with the linear regression case, she has two concerns about her model:\n",
    "overfitting and generalizability (she is not selling homes that were in the\n",
    "dataset it was trained on; still, can she use this model for clients?). \n",
    "\n",
    "Next, we'll introduce regularization to our model to address overfitting with some \n",
    "graphs to see the effects.\n",
    "\n",
    "Run the cell below to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "ridge = linear_model.LogisticRegression(penalty='l2')\n",
    "title = 'ROC Curve for Multivariate Logistic Regression with' +\\\n",
    "        ' Ridge Regularization'\n",
    "plot_roc(X, target_mean, ridge, title)\n",
    "equn_ridge = write_equn(X,target_mean, ridge)\n",
    "print(\"The model found by Ridge Regression:\\n{}\\n\".format(equn_ridge))\n",
    "\n",
    "# LASSO regression\n",
    "lasso = linear_model.LogisticRegression(penalty='l1')\n",
    "title = 'ROC Curve for Multivariate Logistic Regression with' +\\\n",
    "        ' Lasso Regularization'\n",
    "plot_roc(X, target_mean, lasso, title)\n",
    "equn_lasso = write_equn(X,target_mean, lasso)\n",
    "print(\"The model found by LASSO Regression:\\n{}\\n\".format(equn_lasso))\n",
    "\n",
    "# Elastic-Net regression\n",
    "scaler = StandardScaler()\n",
    "enet_data = X.copy()\n",
    "scaler.fit(enet_data)\n",
    "enet_data = scaler.transform(enet_data)\n",
    "el_net = linear_model.SGDClassifier(loss='log', penalty='elasticnet')\n",
    "title = 'ROC Curve for Multivariate Logistic Regression with' +\\\n",
    "        ' Elastic Net Regularization'\n",
    "plot_roc(enet_data, target_mean, el_net, title)\n",
    "equn_el_net = write_equn(X,target_mean, el_net)\n",
    "print(\"The model found by Elastic Net Regression:\\n{}\\n\".format(equn_el_net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "She sees she can use either Ridge or LASSO regularization with her model.\n",
    "The area under the ROC curve for Ridge and LASSO are greater than 0.94. Elastic\n",
    "Net has an area under the curve of 0.77. Either Ridge or LASSO are good \n",
    "candidates to combat overfitting without losing predictive ability. \n",
    "Unfortunately, there is some loss of predictive ability with Elastic Net \n",
    "regularization.  \n",
    "\n",
    "# Cross-Validation\n",
    "Next, she will try a train/test split of the data. It will give  her a chance \n",
    "to test her model on data it hasn't yet seen instead of using her clients as \n",
    "guinea pigs.\n",
    "\n",
    "Run the cell below to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    }
   },
   "outputs": [],
   "source": [
    "# split data into train/test sets and show fit \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,target_mean, random_state=0)\n",
    "\n",
    "title = 'ROC Curve for Multivariate Logistic Regression (train set)'\n",
    "plot_roc(X_train, y_train, log, title)\n",
    "equn_train = write_equn(X_train, y_train, log)\n",
    "print(\"The model found for the train dataset:\\n{}\\n\".format(equn_train))\n",
    "\n",
    "title = 'ROC Curve for Multivariate Logistic Regression (test set)'\n",
    "plot_roc(X_test, y_test, log , title)\n",
    "equn_test = write_equn(X_test, y_test, log)\n",
    "print(\"The model found for the test dataset:\\n{}\\n\".format(equn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "The area under ROC for the train set is 0.96 and 0.91 for the test set.\n",
    "The model applied to the test data doesn't do as well as on the train data, as\n",
    "she would expect. This happens because the model learned on the train set, and\n",
    "it is seeing the test data for the first time. Because there was no big fall in\n",
    "performance (area fell from .96 to .91) from train to test, she\n",
    "can be confident in using her model with her clients.\n",
    "\n",
    "To sum up, a client came to the real estate agent interested to know \n",
    "whether adding a room to his home would pay off for him by increasing its value\n",
    "above the mean for his neighborhood. This question has a yes or no answer, so\n",
    "it is a classification problem-a perfect fit for a classification model like\n",
    "logistic regression. She used regularization to reduce overfitting, which is the \n",
    "tendency to learn the dataset's idiosyncracies too closely. And, she used a train/test \n",
    "split (cross-validation) so she could be confident her model worked on unseen \n",
    "data, rather than testing on her clients. Multivariate Logistic Regression \n",
    "makes for a great tool in her tool belt when asking yes/no type questions about \n",
    "her clients' homes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
