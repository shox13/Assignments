{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telling a Story with Data\n",
    "Businesses need to make decisions now about spending money for the future, yet the uncertainty \n",
    "of the future makes this difficult. In this coding exercise, we'll use linear and logistic \n",
    "regression to make predictions and tell two stories with data. \n",
    "\n",
    "In part 1, we'll use linear regression to determine whether a food truck owner should expand to a new city.\n",
    "\n",
    "In part 2, we'll use logistic regression to determine whether students are likely to pass a course based on their past test score and predicted score for an upcoming test.\n",
    "\n",
    "## Preliminary Step: Create Infrastructure\n",
    "Run the following cell to load all the libraries and custom built functions that \n",
    "we'll need for this exercise. After running the cell, you will see text below indicating that needed libraries are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-plot\n",
    "import scikitplot as skp\n",
    "\n",
    "from scikitplot.metrics import plot_roc\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_regr(X, y, regr):\n",
    "    regr.fit(X, y)\n",
    "    plt.plot(X, y, 'o', label = 'Data')\n",
    "    y_pred = regr.predict(X)\n",
    "    label = 'y = %.2f + %.2f*x' % (regr.intercept_, regr.coef_)\n",
    "    plt.plot(X, y_pred, '-b', label = label)\n",
    "    title = \"Truck Profit (y) vs. City Population (x)\"\n",
    "    plt.xlabel(\"City Population (10,000s)\")\n",
    "    plt.ylabel(\"Truck Profit ($10,000s)\")\n",
    "    y_pred = regr.predict(X)\n",
    "    text = \"$R^2$ = %.2f\" % r2_score(y_pred, y)\n",
    "    plt.text(13.75, 21, text)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_log(X, y, clf):\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    plt.figure(figsize = (8,8))\n",
    "    passed = np.where(y == 1)[0]\n",
    "    failed = np.where(y == 0)[0]\n",
    "    plt.plot(X[passed,0], X[passed,1], '+', label = 'Passed')\n",
    "    plt.plot(X[failed,0], X[failed,1], 'o', label = 'Failed')\n",
    "    plt.xlabel(\"Exam 1 Score\")\n",
    "    plt.ylabel(\"Exam 2 Score\")\n",
    "    plt.title(\"Predicting Pass Rates with Logistic Regression\")\n",
    "    coeff = np.insert(clf.coef_, 0, clf.intercept_)\n",
    "    coeff = coeff / coeff[2]\n",
    "    coeff[:2] = -1 * coeff[:2]\n",
    "    pred = lambda x: coeff[0] + coeff[1]*x\n",
    "    x_min, x_max = X[:,0].min(), X[:,0].max() \n",
    "    t = np.arange(x_min, x_max)\n",
    "    plt.plot(t, pred(t), '-b', label = 'Decision Boundary')\n",
    "    text = 'y = %.2f + %.2f*x' % (coeff[0], coeff[1])\n",
    "    plt.text(60, 30, text)\n",
    "    y_pred = clf.predict(X)\n",
    "    text2 = \"$R^2$ = %.2f\" % r2_score(y_pred, y)\n",
    "    plt.text(60, 25, text2)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_sigmoid():\n",
    "    s = lambda x: 1 / (1 + np.exp(-x))\n",
    "    t = np.arange(-10, 10, .5)\n",
    "    plt.plot(t, s(t), '-b')\n",
    "    a = np.arange(-10, 0, .5)\n",
    "    plt.plot(a, [0.5]*len(a), '--r')\n",
    "    b = np.arange(0, 0.5, .01)\n",
    "    plt.plot([0]*len(b), b, '--r')\n",
    "    plt.annotate('A common threshold: 50%', xy=(0, 0.5), xytext=(1, .65),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    plt.title(\"The Sigmoid Function\")\n",
    "    plt.xlabel(\"$X$\")\n",
    "    plt.ylabel(\"$P(X)$\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_gd(X, y, theta, Js):\n",
    "    fig, (ax0, ax1) = plt.subplots(1,2, figsize = (10, 10))\n",
    "    ax0.plot(X, y, 'o', label = 'Data')\n",
    "    label = 'y = %.2f + %.2f*x' % (theta[0], theta[1])\n",
    "    # mod X to make math work\n",
    "    X_mod = np.insert(X, 0, 1, axis = 1)\n",
    "    y_pred = X_mod.dot(theta)\n",
    "    ax0.plot(X, y_pred, '-b', label = label)\n",
    "    ax0.set_xlabel(\"City Population (10,000s)\")\n",
    "\n",
    "    text = \"$R^2$ = %.2f\" % r2_score(y_pred, y)\n",
    "    ax0.text(6, 22, text)\n",
    "    ax0.set_ylabel(\"Truck Profit ($10,000s)\")\n",
    "    ax0.set_title(\"Truck Profit (y) vs. City Population (x)\")\n",
    "    ax0.legend()\n",
    "\n",
    "    t = np.arange(1, len(Js)+1)\n",
    "    ax1.plot(t, Js, '.') \n",
    "    ax1.set_xlabel(\"Iteration\")\n",
    "    ax1.set_ylabel(\"Cost (MSE)\")\n",
    "    ax1.set_title(\"Gradient Descent Cost Minimization\")\n",
    "    plt.show()\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    # insert columns of ones to make math work\n",
    "    X = np.insert(X, 0, 1, axis = 1)\n",
    "    n_rows, n_cols = X.shape\n",
    "    J_hist = np.zeros(iterations)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "\n",
    "        J = 0\n",
    "        temps = np.zeros(n_cols)\n",
    "        grads = np.zeros(n_cols)\n",
    "\n",
    "        # our prediction\n",
    "        h = lambda a: a.dot(theta)\n",
    "\n",
    "        # cost function is mean-squared-error\n",
    "        for i in range(n_rows):\n",
    "            J += ( h(X[i, :]) - y[i] )**2 / (2*n_rows)\n",
    "        J_hist[_] = J\n",
    "\n",
    "        # compute gradients and place in temp. variable\n",
    "        for j in range(n_cols):\n",
    "            for i in range(n_rows):\n",
    "                grads[j] += ( h(X[i, :]) - y[i] ) * X[i,j] / n_rows\n",
    "\n",
    "            temps[j] = theta[j]- alpha*grads[j]\n",
    "\n",
    "        # simultaneous update\n",
    "        for j in range(n_cols):\n",
    "            theta[j] = temps[j]\n",
    "\n",
    "    return theta, J_hist\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Predict Food Truck Profitability with Linear Regression\n",
    "In this part, we'll examine the case of a food truck owner who is interested in expanding \n",
    "to a new city, but first wants to determine whether this idea is likely to be profitable. To \n",
    "increase our confidence in the results, we'll use two different tools, the sklearn library and \n",
    "the gradient descent algorithm, to run two linear regression operations that show the relationship \n",
    "between city population and food truck profitability. \n",
    "### Run a Linear Regression with the sklearn Library \n",
    "The first linear regression we'll run uses **sklearn**, a pre-built Python library. Run the following \n",
    "cell to load historical food truck data and create a plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'ex1data1.txt'\n",
    "data = pd.read_csv(address, header = None).values\n",
    "\n",
    "X, y = data[:,:-1], data[:,-1]\n",
    "regr = linear_model.LinearRegression()\n",
    "plot_regr(X, y, regr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that a relationship does exist between the population of a city and the \n",
    "profitability of food trucks in that city.\n",
    "\n",
    "### Run a Linear Regression with the Gradient Descent Algorithm\n",
    "Next, we'll use an algorithm called **gradient descent** to run a second linear regression. \n",
    "We have customized this algorithm for our situation. \n",
    "\n",
    "Run the following cell to create a plot of the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_theta = np.zeros(2)\n",
    "learning_rate = .01\n",
    "iterations = 1000\n",
    "\n",
    "theta, J_hist = gradient_descent(X, y, initial_theta, \n",
    "                                learning_rate, iterations)\n",
    "\n",
    "plot_gd(X, y, theta, J_hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the plot that we created using sklearn, this plot shows that the population of a \n",
    "city relates to the profitability of food trucks in that city. \n",
    "\n",
    "#### More Information: Gradient Descent \n",
    "Linear regression works by minimizing the residuals between the prediction and  \n",
    "true values. The gradient descent algorithm minimizes this cost function. \n",
    "\n",
    "To understand how gradient descent works, imagine you're on top of a hill, blindfolded,  \n",
    "and want to go down the hill. Which direction should you go? You can feel which way leads  \n",
    "down most steeply, so you go that direction, and continue to feel for the direction of  \n",
    "steepest descent until you reach the bottom of the hill. Gradient descent works similarly,  \n",
    "until it reaches the minimum of the cost function. \n",
    "\n",
    "### Interpret the Linear Regression Results \n",
    "The answers from the sklearn library and the gradient descent algorithm are fairly equal. Both \n",
    "plots show that a relationship exists between the population of a city and the profitability of \n",
    "food trucks in that city. We can be confident that a relationship exists between city population \n",
    "and food truck profitability. This prediction is not completely certain, but does eliminate some risk. \n",
    "#### More Information: $R^2$ \n",
    "The gradient descent graph includes an equation for a prediction and an $R^2$ value. The\n",
    "coefficients of the equation describe the sensitivity of profit to changes in\n",
    "population:\n",
    "\n",
    "- The intercept indicates that if a food truck owner adds a food truck in a town that has \n",
    "zero residents, the food truck owner will lose $32,400.\n",
    "\n",
    "- The coefficient of x indicates that for every increase in city population by 10,000, \n",
    "the truck will make an additional $11,300.\n",
    "\n",
    "The $R^2$ value describes how well our prediction models fit the data used to \n",
    "train it. $R^2$:\n",
    "\n",
    "- is in [0,1]\n",
    "- the closer to one, the more the model explains the variance in the data. \n",
    "\n",
    "\n",
    "# Part 2: Predict Student Outcomes with Logistic Regression\n",
    "In this part, we'll determine whether students who earn specific scores on two tests are\n",
    "likely to pass a course. We'll use logistic regression, which provides \"yes/no\" \n",
    "or \"true/false\" answers to questions based on two variables.\n",
    "## Run a Logistic Regression with the sklearn Library \n",
    "This logistic regression we'll run uses the sklearn library that we used in part 1. Run \n",
    "the following cell to load a dataset of exam scores that are labelled as either passing or failing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'ex2data1.txt'\n",
    "data = pd.read_csv(address, header = None).values\n",
    "X = data[:,:-1]; y = data[:,-1]\n",
    "clf = linear_model.LogisticRegression(solver='lbfgs')\n",
    "plot_log(X, y, clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Use Logistic Regression to Predict an Outcome \n",
    "Now that we've loaded the dataset, we can make predictions about student outcomes. \n",
    "\n",
    "In this example, a student scored 50 on the first exam because she was sick. She thinks \n",
    "she can score 90 on the next exam.\n",
    "\n",
    "Run the following cell to determine whether this student, based on past data, is likely to pass the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array([[50, 90]])\n",
    "prob_pass = clf.predict(data_array)\n",
    "print(\"The probability of passing with %s: %.2f\" % (data_array, prob_pass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with scores of 50 and 90, she is likely to pass the course. You can experiment by changing the `50` and `90` in the first line of code in the cell above and observing how the results change.\n",
    "\n",
    "## Exercise: Use Logistic Regression to Predict an Outcome\n",
    "What is the likelihood that a student who makes a 60 on exam 1 and a 64 on exam 2 passes the course?\n",
    "\n",
    "Enter the values for the `data_array` and `prop_pass` variables below, using the previous cell as an example.\n",
    "\n",
    "Try it first.  You can check your code against the answer in the cell that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------Enter Your Code Here------------#\n",
    "data_array = \n",
    "prob_pass = \n",
    "print(\"The probability of passing with %s: %.2f\" % (data_array, prob_pass))\n",
    "#-------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Code\n",
    "We used the following code in the cell above.\n",
    "\n",
    "```python\n",
    "#-----------Enter Your Code Here------------#\n",
    "data_array = np.array([[60, 64]])\n",
    "prob_pass = clf.predict(data_array)\n",
    "print(\"The probability of passing with %s: %.2f\" % (data_array, prob_pass))\n",
    "#-------------------------------------------#\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the Logistic Regression Results\n",
    "\n",
    "Logistic regression uses the sigmoid function to answer a yes/no question. \n",
    "#### The Sigmoid Function\n",
    "Logistic regression works similarly to linear regression by finding weights through\n",
    "gradient descent that minimize its cost function (something different than the\n",
    "residuals). \n",
    "\n",
    "It takes the dot product of exam scores and solved-coefficients to\n",
    "come up with a real-value. Next, it turns that value into a probability by \n",
    "passing it through the sigmoid function. Finally, each training example of exam\n",
    "scores is classified as passing or not based on a chosen probability threshold,\n",
    "usually 50%. \n",
    "\n",
    "The sigmoid function is very useful because it maps all real-values to (0, 1).\n",
    "\n",
    "To see this visually, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, no matter how large X is, P(X) is no higher than 1. Likewise,\n",
    "no matter how small X, P(x) is no lower than 0. \n",
    "\n",
    "#### The Coefficients\n",
    "The process for interpreting the coefficients in logistic regression is similar \n",
    "to the process for linear regression. The difference is we talk in terms of percentages instead of\n",
    "real-values.\n",
    "\n",
    "- The intercept can be interpreted as the as the minimum exam 2 score required\n",
    "  to pass. If you score 0 on exam 1, our model says you need to score ~125%\n",
    "  on exam 2.\n",
    "- The coefficient of x is interpreted as the change in exam 2 score required \n",
    "  to pass for a 1% increase in exam 1 score. If you score 1% higher on exam 1,\n",
    "  you will need 1.02% less on exam 2 in order to pass.\n",
    "\n",
    "\n",
    "## ROC curves\n",
    "ROC curves give us a way to compare the rate of correctly passing exam scores\n",
    "(predicted) to the rate of falsely passing exam scores (predicted). If you\n",
    "change the classification threshold (usually 50%), these values will vary, which is what\n",
    "produces the curve. Let's take a look at the ROC for the exam scores.\n",
    "\n",
    "Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.fit(X, y).predict_proba(X)\n",
    "        \n",
    "# FPR(T) and TPR(T) are functions of the acceptance threshold T\n",
    "# the roc plots the (fpr, tpr) pairs that result from varying T\n",
    "plot_roc(y, y_pred)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the point (0,0.6) for class 1; it is telling you that for the\n",
    "chosen pass threshold, you can expect a false-positive (FPR) rate of 0% and a\n",
    "true-positive rate (TPR) of 60%. A perfect score would be 100%, which would happen\n",
    "if the curve was in the far left corner of the graph. This also corresponds to \n",
    "an area under the curve of 1.\n",
    "\n",
    "Google is famous for not wanting any false positives in its hiring decisions, \n",
    "so the company might choose a threshold with a 0% FPR.\n",
    "\n",
    "## Conclusion: The Story the Data Tells\n",
    "In this exercise, we saw how a food truck owner can use linear regression to predict \n",
    "how profitable a new truck in a new city will be. \n",
    "\n",
    "We then saw how a student could use logistic regression to predict\n",
    "what score she would need on an exam to be fairly confident that she would pass the course.\n",
    "\n",
    "These tools are effective for simple problems, but business data is often more complicated \n",
    "and has more variables. We'll learn about multivariable regression in the next coding exercise. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
